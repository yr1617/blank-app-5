"""
Streamlit ì•±: ê¸°í›„ë³€í™” - í•´ì–‘ìƒíƒœê³„ ëŒ€ì‹œë³´ë“œ
ì‘ì„±ì: ChatGPT (í•œêµ­ì–´ UI)

ê³µê°œ ë°ì´í„° ë³€ê²½:
 - BCO-DMO â€˜global_bleaching_environmental.csvâ€™ ì‚¬ìš© (1980-2020) :contentReference[oaicite:1]{index=1}

ë³´ê³ ì„œ ë‚´ìš© ë°˜ì˜:
 - ì‚°í˜¸ ë°±í™”, í•´ì–‘ ì‚°ì„±í™”, ê³ ìˆ˜ì˜¨, ì–´ë¥˜ íì‚¬ ë“±
 - ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œì— ì–´ë¥˜ íì‚¬ ê´€ë ¨ ì§€í‘œ í•©ì„± ê°•í™”
"""

import io
import os
import time
import tempfile
from datetime import datetime
from typing import Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import pytz
import requests
import streamlit as st

# ------------------ ì„¤ì • ------------------
LOCAL_TZ = pytz.timezone("Asia/Seoul")
def seoul_today():
    return datetime.now(LOCAL_TZ).date()

def drop_future_dates(df: pd.DataFrame, date_col: str = "date") -> pd.DataFrame:
    if date_col not in df.columns:
        return df
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    df = df[~(df[date_col].dt.date > seoul_today())]
    return df

def retry_get(url: str, timeout: int = 15, retries: int = 3, backoff: float = 1.5):
    last_exc = None
    for i in range(retries):
        try:
            resp = requests.get(url, timeout=timeout)
            resp.raise_for_status()
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff ** (i + 1))
    raise last_exc

def standardize_timeseries(df: pd.DataFrame, date_col_candidates=None, value_col_candidates=None) -> pd.DataFrame:
    df = df.copy()
    if date_col_candidates is None:
        date_col_candidates = ["date", "year", "survey_date"]
    if value_col_candidates is None:
        value_col_candidates = ["bleaching", "bleaching_presence", "bleaching_rate", "value"]
    # date
    date_col = None
    for c in date_col_candidates:
        if c in df.columns:
            date_col = c
            break
    if date_col:
        df["date"] = pd.to_datetime(df[date_col], errors="coerce")
    else:
        df["date"] = pd.NaT
    # value
    value_col = None
    for c in value_col_candidates:
        if c in df.columns:
            value_col = c
            break
    if value_col:
        df["value"] = pd.to_numeric(df[value_col], errors="coerce")
    else:
        # fallback: count of bleaching presence if possible
        if "bleaching_presence" in df.columns:
            df["value"] = df["bleaching_presence"]
        else:
            df["value"] = np.nan
    # group optional
    group_cols = [c for c in ["site", "region", "country"] if c in df.columns]
    df["group"] = df[group_cols[0]] if group_cols else None
    # drop duplicates
    df = df.drop_duplicates().reset_index(drop=True)
    # remove future dates
    df = drop_future_dates(df, date_col="date")
    return df[["date", "value", "group"]]

# ------------------ ê³µê°œ ë°ì´í„° ì†ŒìŠ¤ ------------------
BLEACHING_ENV_URL = "https://www.bco-dmo.org/dataset/773466/files/global_bleaching_environmental.csv"  # BCO-DMO ê³µê°œ CSV :contentReference[oaicite:2]{index=2}

@st.cache_data(ttl=3600)
def load_bleaching_env():
    resp = retry_get(BLEACHING_ENV_URL, timeout=20, retries=3)
    df = pd.read_csv(io.BytesIO(resp.content), low_memory=False)
    return df

# ì˜ˆì‹œ SST / ì‚°ì„±í™” / ì–´ë¥˜ íì‚¬ synthetic ë˜ëŠ” ë³´ì¡° ë°ì´í„°
@st.cache_data(ttl=3600)
def load_example_sst_acid_mortality():
    coral = pd.DataFrame({
        "date": pd.date_range(start="1980-01-01", periods=45, freq="Y"),
        "bleaching_rate_percent": np.clip(np.linspace(10, 70, 45) + np.random.randn(45)*4, 0, 100)
    })
    sst = pd.DataFrame({
        "date": pd.date_range(start="1980-01-01", periods=45, freq="Y"),
        "sst_anomaly": np.clip(np.linspace(0, 1.5, 45) + np.random.randn(45)*0.2, -1, 2)
    })
    acid = pd.DataFrame({
        "date": pd.date_range(start="1980-01-01", periods=45, freq="Y"),
        "surface_pH": np.clip(8.2 - np.linspace(0, 0.15, 45) + np.random.randn(45)*0.01, 7.7, 8.3)
    })
    # fish mortality synthetic based on sst & acid
    merged = pd.merge(coral.rename(columns={"bleaching_rate_percent":"bleaching_rate"}), sst, on="date", how="outer")
    merged = pd.merge(merged, acid, on="date", how="outer")
    merged = merged.sort_values("date").reset_index(drop=True)
    merged["sst_norm"] = (merged["sst_anomaly"] - merged["sst_anomaly"].min()) / (merged["sst_anomaly"].max() - merged["sst_anomaly"].min() + 1e-9)
    merged["pH_drop"] = 8.2 - merged["surface_pH"]
    merged["pH_norm"] = (merged["pH_drop"] - merged["pH_drop"].min()) / (merged["pH_drop"].max() - merged["pH_drop"].min() + 1e-9)
    merged["fish_mortality_index"] = (0.7 * merged["sst_norm"].fillna(0) + 0.3 * merged["pH_norm"].fillna(0)) * 100
    return coral, sst, acid, merged

# ------------------ ì•± UI ------------------

# í°íŠ¸ ì‹œë„
PRETENDARD_PATH = "/fonts/Pretendard-Bold.ttf"
try:
    if os.path.exists(PRETENDARD_PATH):
        st.markdown(f"""
            <style>
            @font-face {{
                font-family: 'PretendardCustom';
                src: url('{PRETENDARD_PATH}');
            }}
            html, body, [class*="css"] {{
                font-family: 'PretendardCustom', sans-serif;
            }}
            </style>
            """, unsafe_allow_html=True)
except:
    pass

st.set_page_config(page_title="í•´ì–‘ìƒíƒœê³„ & ê¸°í›„ë³€í™” ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸŒŠ í•´ì–‘ìƒíƒœê³„ & ê¸°í›„ë³€í™” ëŒ€ì‹œë³´ë“œ")
st.caption("ê³µê°œ ë°ì´í„° + ì‚¬ìš©ì ì…ë ¥(ë³´ê³ ì„œ) ê¸°ë°˜ â€” í•œêµ­ì–´ UI")

# ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ
st.header("ğŸ“Œ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (GCBD ëŒ€ì²´: BCO-DMO Bleaching & Environmental)")

public_data_warn = None
try:
    with st.spinner("ê³µê°œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘..."):
        df_raw = load_bleaching_env()
        # í‘œì¤€í™”: ë‚ ì§œ, value (presence or bleaching_rate), group
        df_std = standardize_timeseries(df_raw, date_col_candidates=["date","survey_date"], value_col_candidates=["bleaching","bleaching_presence","percent_bleached"])
        if df_std["value"].notna().sum() < 3:
            raise RuntimeError("ë°ì´í„° ë‚´ë¶€ì— ì˜ë¯¸ ìˆëŠ” ìˆ˜ì¹˜(value) í•­ëª©ì´ ë¶€ì¡±í•¨")
        gcbd_df = df_std
        st.success("âœ… ê³µê°œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ (BCO-DMO Bleaching & Environmental ë°ì´í„°) å‡ºå…¸: BCO-DMO") 
        st.caption(f"ì¶œì²˜ URL: {BLEACHING_ENV_URL}")
except Exception as e:
    public_data_warn = f"ê³µê°œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}"
    st.warning(public_data_warn)
    coral_ex, sst_ex, acid_ex, merged_ex = load_example_sst_acid_mortality()
    gcbd_df = coral_ex.rename(columns={"bleaching_rate_percent":"value"}).copy()
    gcbd_df["group"] = None
    st.info("ëŒ€ì²´ ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš© ì¤‘")

gcbd_df = gcbd_df.drop_duplicates().reset_index(drop=True)
gcbd_df = drop_future_dates(gcbd_df, date_col="date")

# ì˜µì…˜: ê¸°ê°„ í•„í„° / ìŠ¤ë¬´ë”©
st.sidebar.header("ê³µê°œ ë°ì´í„° ì˜µì…˜")
min_date = gcbd_df["date"].min()
max_date = gcbd_df["date"].max()
if pd.isna(min_date) or pd.isna(max_date):
    min_date = datetime(1980,1,1).date()
    max_date = seoul_today()
date_range = st.sidebar.slider("ê¸°ê°„ ì„ íƒ", min_value=min_date, max_value=max_date,
                               value=(min_date, max_date))
smoothing = st.sidebar.selectbox("ìŠ¤ë¬´ë”©", options=["ì‚¬ìš© ì•ˆ í•¨","3ë…„","5ë…„"], index=0)

mask = (gcbd_df["date"].dt.date >= date_range[0]) & (gcbd_df["date"].dt.date <= date_range[1])
plot_df = gcbd_df.loc[mask].copy()

# ì—° ë‹¨ìœ„ ìš”ì•½
plot_df["year"] = plot_df["date"].dt.year
annual = plot_df.groupby("year")["value"].mean().reset_index()
annual["date"] = pd.to_datetime(annual["year"].astype(str) + "-01-01")

viz = annual.copy()
if smoothing != "ì‚¬ìš© ì•ˆ í•¨":
    window = 3 if smoothing == "3ë…„" else 5
    viz["value_smoothed"] = viz["value"].rolling(window=window, center=True, min_periods=1).mean()
else:
    viz["value_smoothed"] = viz["value"]

st.subheader("ì‚°í˜¸ ë°±í™” í˜„ìƒ ë¹„ìœ¨ (ì—°ë³„ í‰ê· )")
fig = px.line(viz, x="date", y="value_smoothed",
              labels={"date":"ì—°ë„", "value_smoothed":"ë°±í™” ë¹„ìœ¨ (í‰ê· )"},
              title="ê³µê°œ ë°ì´í„°: ì‚°í˜¸ ë°±í™” ë¹„ìœ¨ ë³€í™” ì¶”ì„¸")
fig.update_traces(mode="lines+markers")
st.plotly_chart(fig, use_container_width=True)
csv_buf = viz[["date","value_smoothed"]].rename(columns={"value_smoothed":"value"}).to_csv(index=False).encode("utf-8")
st.download_button("ê³µê°œ ë°ì´í„° ì‚°í˜¸ë°±í™” ì „ì²˜ë¦¬ CSV ë‹¤ìš´ë¡œë“œ", data=csv_buf, file_name="public_bleaching_timeseries.csv", mime="text/csv")

# ì‚¬ìš©ì ì…ë ¥(ë³´ê³ ì„œ) ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ
st.markdown("---")
st.header("ğŸ“ ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ (ë³´ê³ ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©)")

st.markdown("**ë³´ê³ ì„œ ë‚´ìš© ìš”ì•½**")
st.write("""
- ìµœê·¼ ìˆ˜ì‹­ ë…„ê°„ ì§€êµ¬ ì˜¨ë‚œí™”ë¡œ ì¸í•´ í•´ìˆ˜ì˜¨ê³¼ í•´ìˆ˜ë©´ì´ ìƒìŠ¹í•˜ê³  ìˆìŒ  
- í•´ìˆ˜ì˜¨ ìƒìŠ¹ â†’ ì‚°í˜¸ ë°±í™”, ì–´ë¥˜ íì‚¬  
- í•´ì–‘ ì‚°ì„±í™”ê°€ ì¡°ê°œë¥˜/ì‚°í˜¸ ê»ì§ˆ ì†ìƒ ë° ìƒë¬¼ ë‹¤ì–‘ì„± ê°ì†Œ  
- ê³ ìˆ˜ì˜¨ í•´ì–‘ ì—´íŒŒ ë“±ì´ ìƒíƒœê³„ ë¶•ê´´ ê°€ì†  
- í•´ê²°ì±…: íƒ„ì†Œ ë°°ì¶œ ì €ê°, í•´ì–‘ ë³´í˜¸êµ¬ì—­ í™•ëŒ€, ì‚°í˜¸ ë³µì›, ê°œì¸ ë° ì •ì±… ì‹¤ì²œ
""")

# ë³¸ë¡ 1: ìµœê·¼ 45ë…„ê°„ ì‚°í˜¸ ë°±í™” ë¹„ìœ¨
st.subheader("ë³¸ë¡ 1 â€” ìµœê·¼ 45ë…„ê°„ ì‚°í˜¸ ë°±í™” ë¹„ìœ¨ (ë³´ê³ ì„œìš©)")
report_df = gcbd_df.copy()
if report_df.shape[0] < 45:
    # ëª¨ìëŒ: ì˜ˆì‹œ í–‰ ì¶”ê°€
    coral_ex, _, _, _ = load_example_sst_acid_mortality()
    # use example to pad or replace
    report_df = coral_ex.rename(columns={"bleaching_rate_percent":"value"}).copy()
report_df = report_df.sort_values("date").reset_index(drop=True)
if report_df.shape[0] >= 45:
    report_plot = report_df.tail(45).copy()
else:
    report_plot = report_df.copy()

fig1 = px.area(report_plot, x="date", y="value",
              labels={"date":"ì—°ë„", "value":"ì‚°í˜¸ ë°±í™”ìœ¨ (ì„ì˜ë‹¨ìœ„)"},
              title="ë³´ê³ ì„œìš©: ìµœê·¼ 45ë…„ê°„ ì‚°í˜¸ ë°±í™”ìœ¨ ë³€í™”")
st.plotly_chart(fig1, use_container_width=True)
st.download_button("ë³´ê³ ì„œ 45ë…„ ì‚°í˜¸ë°±í™” ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", data=report_plot.to_csv(index=False).encode("utf-8"),
                   file_name="report_bleaching_45y.csv", mime="text/csv")

# ë³¸ë¡ 2: í•´ì–‘ ì‚°ì„±í™”, ê³ ìˆ˜ì˜¨, ì–´ë¥˜ íì‚¬ ì˜í–¥ ë³µí•© ì‹œê°í™”
st.subheader("ë³¸ë¡ 2 â€” í•´ì–‘ ì‚°ì„±í™” Â· ê³ ìˆ˜ì˜¨ Â· ì–´ë¥˜ íì‚¬ ì˜í–¥ ë¹„êµ (í•©ì„± ì§€í‘œ)")

# ì˜ˆì‹œ SST, pH, mortality merge
_, sst_ex, acid_ex, merged_ex = load_example_sst_acid_mortality()
acid_ex["date"] = pd.to_datetime(acid_ex["date"], errors="coerce")
sst_ex["date"] = pd.to_datetime(sst_ex["date"], errors="coerce")
merged_ex = merged_ex.sort_values("date").reset_index(drop=True)
merged_ex = drop_future_dates(merged_ex, date_col="date")

fig2 = px.line(merged_ex, x="date", y="bleaching_rate",
              labels={"date":"ì—°ë„","bleaching_rate":"ë°±í™”ìœ¨ (ì„ì˜ë‹¨ìœ„)"},
              title="ë³´ê³ ì„œìš©: ì‚°ì„±í™”Â·ê³ ìˆ˜ì˜¨Â·ì–´ë¥˜ íì‚¬ ì˜í–¥ ë¹„êµ")
fig2.add_scatter(x=merged_ex["date"], y=merged_ex["sst_anomaly"], mode="lines+markers", name="SST ì´ìƒì¹˜ (Â°C)")
fig2.add_scatter(x=merged_ex["date"], y=merged_ex["fish_mortality_index"], mode="lines+markers", name="ì–´ë¥˜ íì‚¬ ì§€ìˆ˜ (í•©ì„±)")
st.plotly_chart(fig2, use_container_width=True)
st.download_button("ë³¸ë¡ 2 í•©ì„± ì§€í‘œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", data=merged_ex.to_csv(index=False).encode("utf-8"),
                   file_name="report_composite_mortality.csv", mime="text/csv")

# ê²°ë¡  / ê¶Œê³ 
st.markdown("---")
st.subheader("ê²°ë¡  ë° ê¶Œê³ ")
st.write("""
- ì‚°í˜¸ ë°±í™”ìœ¨ì˜ ì¦ê°€ ì¶”ì„¸ê°€ ê³µê°œ ë°ì´í„°ì—ì„œë„ í™•ì¸ë¨  
- í•´ì–‘ ì‚°ì„±í™”ì™€ ê³ ìˆ˜ì˜¨ì´ ìƒíƒœê³„ ì••ë°• ìš”ì¸ìœ¼ë¡œ ì‘ìš©í•˜ë©°, ì´ë“¤ì´ ì–´ë¥˜ íì‚¬ ë° ìƒë¬¼ ë‹¤ì–‘ì„± ê°ì†Œì™€ ì—°ê²°ë¨  
- ê¶Œê³ ì‚¬í•­:
  1. ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œ ê°ì¶• ë° í•´ì–‘ ì˜¨ë„ ìƒìŠ¹ ì™„í™”  
  2. í•´ì–‘ ë³´í˜¸êµ¬ì—­ í™•ëŒ€ ë° ì‚°í˜¸ ë³µì› í”„ë¡œì íŠ¸ ì§€ì›  
  3. í•´ì–‘ ì‚°ì„±í™” ëŒ€ì‘ ì—°êµ¬ ê°•í™” (pH ë³€í™” ì¶”ì )  
  4. ì¼ë°˜ ì‹œë¯¼ì˜ í–‰ë™ ì‹¤ì²œ: ë…¸í”Œë¼ìŠ¤í‹±, ì—ë„ˆì§€ ì ˆì•½, ì§€ì† ê°€ëŠ¥í•œ ì‹ìŠµê´€
""")

# ì°¸ê³ ìë£Œ
st.markdown("**ì°¸ê³ ìë£Œ**")
st.write(f"- BCO-DMO Bleaching & Environmental CSV: {BLEACHING_ENV_URL}")
st.write("- NOAA Coral Reef Watch ì œí’ˆ ì •ë³´: https://coralreefwatch.noaa.gov/product/5km/")
st.write(f"- í•œêµ­ ê´€ë ¨ ë…¼ë¬¸: KISTI ì‚°ì„±í™” í˜„í™©, NIFS ë³´ê³ ì„œ ë“±")
