# streamlit_app.py
"""
Streamlit ì•±: ê¸°í›„ë³€í™” - í•´ì–‘ìƒíƒœê³„ ëŒ€ì‹œë³´ë“œ
ì‘ì„±ì: ChatGPT (í•œêµ­ì–´ UI)
ì„¤ëª…:
 - ìƒë‹¨: ê³µê°œ ë°ì´í„°(ê³µì‹) ëŒ€ì‹œë³´ë“œ
 - í•˜ë‹¨: ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ (í”„ë¡¬í”„íŠ¸ì— ì œê³µëœ ë‚´ìš©ë§Œ ì‚¬ìš©; ì—…ë¡œë“œ ì—†ìŒ)
ì£¼ìš” ê·œì¹™(ì½”ë“œ ì£¼ì„ì—ë„ ì¶œì²˜ ëª…ì‹œ):
 - ê³µê°œ ë°ì´í„° ì†ŒìŠ¤(ì˜ˆì‹œ):
    - Global Coral-Bleaching Database (GCBD, 1980-2020): https://www.nature.com/articles/s41597-022-01121-y
      ë©”íƒ€/ë‹¤ìš´ë¡œë“œ: https://springernature.figshare.com/articles/dataset/Metadata_record_for_A_global_coral-bleaching_database_GCBD_1980_2020/16958353
    - NOAA Coral Reef Watch (í˜„í™©, ìœ„ì„±ê¸°ë°˜): https://coralreefwatch.noaa.gov/
    - NCEI Global Coral Bleaching Database (ë°ì´í„° ë³´ê´€ì†Œ): https://catalog.data.gov/dataset/global-coral-bleaching-database-ncei-accession-0228498
    - NOAA OISST (Sea Surface Temperature - SST): https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html
    - Ocean Carbon & Acidification (OCADS / GLODAP): https://www.ncei.noaa.gov/products/ocean-carbon-acidification-data-system , https://glodap.info/
    - í•œêµ­ ê´€ë ¨ ìë£Œ (ì‚¬ìš©ì ì œê³µ ì°¸ê³  ë§í¬):
        - ìš°ë¦¬ë‚˜ë¼ ì£¼ë³€ ë°”ë‹¤ì˜ ì‚°ì„±í™” í˜„í™©: https://koreascience.kr/article/JAKO202210261284373.page?lang=ko
        - NIFS ê¸°í›„ë³€í™” ì˜í–¥ PDF: https://www.nifs.go.kr/cmmn/file/climatechange_01.pdf
ì£¼ì˜:
 - API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ í›„ ì˜ˆì‹œ ë°ì´í„°(ë‚´ì¥)ë¡œ ëŒ€ì²´í•˜ê³  í™”ë©´ì— ì•ˆë‚´ í‘œì‹œí•©ë‹ˆë‹¤.
 - ëª¨ë“  ë¼ë²¨Â·íˆ´íŒÂ·ë²„íŠ¼ì€ í•œêµ­ì–´ì…ë‹ˆë‹¤.
 - í°íŠ¸: /fonts/Pretendard-Bold.ttf ë¥¼ ì‚¬ìš© ì‹œ ì‹œë„ (ì—†ìœ¼ë©´ ë¬´ì‹œ)
"""

import io
import time
import math
import requests
import pandas as pd
import numpy as np
import plotly.express as px
import streamlit as st
from datetime import datetime, timezone, timedelta, date
from dateutil import parser as dateparser
import pytz
import xarray as xr

# ---------- ì„¤ì • ----------
# ë¡œì»¬ íƒ€ì„ì¡´ (ì‚¬ìš©ì ì§€ì¹¨): Asia/Seoul
LOCAL_TZ = pytz.timezone("Asia/Seoul")

# í°íŠ¸ ì‹œë„(ì—†ìœ¼ë©´ ìë™ ìƒëµ)
FONT_PATH = "/fonts/Pretendard-Bold.ttf"

# ê³µê°œ ë°ì´í„° URL(ìš°ì„  ì‹œë„)
GCBD_METADATA_CSV = "https://figshare.com/ndownloader/files/32677238"  # ë©”íƒ€ë°ì´í„° (ì˜ˆì‹œ: figshare metadata file id may change)
# (ëŒ€ì²´) NCEI Global Coral Bleaching Database (ì„¤ëª…/FTP ë§í¬)
NCEI_GCBD = "https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncei:0228498"

# NOAA Coral Reef Watch (ì •ë³´ í˜ì´ì§€)
NOAA_CRW = "https://coralreefwatch.noaa.gov/"

# SST OISST (ë©”íƒ€/ì ‘ê·¼ í˜ì´ì§€)
NOAA_OISST = "https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html"

# Ocean acidification resource
GLODAP = "https://glodap.info/"
OCADS = "https://www.ncei.noaa.gov/products/ocean-carbon-acidification-data-system"

# ì‚¬ìš©ì ì œê³µ ì°¸ê³  ë§í¬ (í”„ë¡¬í”„íŠ¸)
KCI_KISTI = "https://koreascience.kr/article/JAKO202210261284373.page?lang=ko"
NIFS_PDF = "https://www.nifs.go.kr/cmmn/file/climatechange_01.pdf"

# ---------- ìœ í‹¸ë¦¬í‹° ----------

def seoul_today():
    """Seoul ê¸°ì¤€ 'ì˜¤ëŠ˜' ë‚ ì§œ (ìì • ê¸°ì¤€)"""
    now = datetime.now(LOCAL_TZ)
    return now.date()

def drop_future_dates(df, date_col="date"):
    """date_colì´ datetime ë˜ëŠ” ë¬¸ìì—´ì¸ DataFrameì—ì„œ ì˜¤ëŠ˜(ì„œìš¸ ìì •) ì´í›„ ë°ì´í„° ì œê±°."""
    if date_col not in df.columns:
        return df
    today = seoul_today()
    try:
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    except Exception:
        df[date_col] = df[date_col].apply(lambda x: pd.to_datetime(x, errors='coerce'))
    df = df[~(df[date_col].dt.date > today)]
    return df

def retry_get(url, timeout=10, retries=2, backoff=1.5):
    """ê°„ë‹¨í•œ ì¬ì‹œë„ GET"""
    for i in range(retries+1):
        try:
            resp = requests.get(url, timeout=timeout)
            resp.raise_for_status()
            return resp
        except Exception as e:
            if i < retries:
                time.sleep(backoff ** (i+1))
                continue
            else:
                raise

# ---------- ìºì‹œëœ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ----------

@st.cache_data(ttl=3600)
def load_g_cbd_metadata():
    # wrapper to keep function name valid in cache keys
    # Attempt to download GCBD metadata csv. If fails, raise.
    url = GCBD_METADATA_CSV
    resp = retry_get(url, timeout=15, retries=2)
    # The figshare id provided may point to CSV metadata; attempt to read as CSV
    df = pd.read_csv(io.StringIO(resp.text))
    return df

@st.cache_data(ttl=3600)
def try_download_csv(url):
    resp = retry_get(url, timeout=15, retries=2)
    df = pd.read_csv(io.StringIO(resp.text))
    return df

# ---------- ì˜ˆì‹œ(ëŒ€ì²´) ë°ì´í„° (API/ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©) ----------
EXAMPLE_CORAL = pd.DataFrame({
    "date": pd.date_range(start="1980-01-01", periods=45, freq="Y"),
    "bleaching_rate_percent": np.clip(np.linspace(5, 65, 45) + np.random.randn(45)*3, 0, 100)
})
EXAMPLE_SST = pd.DataFrame({
    "date": pd.date_range(start="1980-01-01", periods=540, freq="M"),
    "sst_anomaly": np.clip(np.linspace(-0.3, 1.2, 540) + np.random.randn(540)*0.1, -2, 3)
})
EXAMPLE_ACID = pd.DataFrame({
    "date": pd.date_range(start="1990-01-01", periods=35, freq="Y"),
    "surface_pH": np.clip(8.2 - np.linspace(0, 0.15, 35) + np.random.randn(35)*0.01, 7.7, 8.3)
})

# ---------- Streamlit UI ----------

st.set_page_config(page_title="í•´ì–‘ìƒíƒœê³„ & ê¸°í›„ë³€í™” ëŒ€ì‹œë³´ë“œ", layout="wide")

# (ì‹œë„) Pretendard í°íŠ¸ ì ìš© (ë¸Œë¼ìš°ì €ê°€ ì—†ì„ ê²½ìš° ë¬´ì‹œë¨)
try:
    with open(FONT_PATH, "rb"):
        st.markdown(
            f"""
            <style>
            @font-face {{
                font-family: 'PretendardCustom';
                src: url('{FONT_PATH}');
            }}
            html, body, [class*="css"]  {{
                font-family: 'PretendardCustom', sans-serif;
            }}
            </style>
            """,
            unsafe_allow_html=True,
        )
except Exception:
    # í°íŠ¸ íŒŒì¼ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë„˜ì–´ê°
    pass

st.title("ğŸŒŠ í•´ì–‘ìƒíƒœê³„ì™€ ê¸°í›„ë³€í™” ëŒ€ì‹œë³´ë“œ")
st.caption("ê³µê°œ ë°ì´í„° ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ + ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°(ë³´ê³ ì„œ) ê¸°ë°˜ ì‹œê°í™” â€” í•œêµ­ì–´ UI")

# ---------- ì„¹ì…˜ 1: ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ ----------
st.header("ğŸ“Œ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (ê³µì‹ ê³µê°œ ë°ì´í„° ì—°ê²° ì‹œë„)")

col1, col2 = st.columns([2,1])

with col2:
    st.markdown("**ë°ì´í„° ì¶œì²˜(ì‹œë„ ì¤‘):**")
    st.write("- Global Coral-Bleaching Database (GCBD) ë©”íƒ€: Scientific Data / Figshare")
    st.write(f"  â€¢ ë…¼ë¬¸: https://www.nature.com/articles/s41597-022-01121-y")
    st.write(f"  â€¢ Figshare metadata/ë‹¤ìš´ë¡œë“œ: {GCBD_METADATA_CSV}")
    st.write("- NOAA Coral Reef Watch: " + NOAA_CRW)
    st.write("- NOAA OISST (SST): " + NOAA_OISST)
    st.write("- Ocean carbon & acidification: " + OCADS)
    st.write("- í•œêµ­ ê´€ë ¨ ì°¸ê³ ìë£Œ: (KISTI) " + KCI_KISTI)
    st.write("- NIFS ë³´ê³ ì„œ PDF: " + NIFS_PDF)

# Try to load GCBD (or fall back)
public_data_warn = None
try:
    # Attempt to download GCBD metadata CSV and process an aggregated timeseries for "% bleaching"
    # NOTE: remote files may vary; this attempt is best-effort. If fails, use example.
    try:
        resp = retry_get(GCBD_METADATA_CSV, timeout=12, retries=2)
        # try to parse as CSV
        try:
            gcbd_df = pd.read_csv(io.StringIO(resp.text))
        except Exception:
            # if not CSV, fallback to example
            raise Exception("GCBD ë©”íƒ€íŒŒì¼ CSV íŒŒì‹± ì‹¤íŒ¨")
        # Attempt to create yearly bleaching rate summary if columns exist
        # Many GCBD metadata include columns like 'year', 'bleaching_percent' or 'bleaching_severity'
        if 'year' in gcbd_df.columns:
            # example aggregation: percent of sites reporting bleaching per year
            temp = gcbd_df.copy()
            temp['year'] = pd.to_numeric(temp['year'], errors='coerce').astype('Int64')
            yearly = temp.groupby('year').apply(lambda g: (g['bleaching']>0).sum() if 'bleaching' in g.columns else len(g)).reset_index(name='count_obs')
            # create bleaching_rate_percent synthetic if not available
            coral_ts = pd.DataFrame({
                'date': pd.to_datetime(yearly['year'].astype(str) + "-01-01"),
                'bleaching_rate_percent': np.clip( (yearly['count_obs'] / yearly['count_obs'].max()) * 100, 0, 100)
            })
        else:
            # fallback: use EXAMPLE_CORAL
            coral_ts = EXAMPLE_CORAL.copy()
            public_data_warn = "GCBD ë©”íƒ€ë°ì´í„°ì—ì„œ ì—°ë„ ì¹¼ëŸ¼ì„ ì°¾ì§€ ëª»í•˜ì—¬ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ì˜€ìŠµë‹ˆë‹¤."
    except Exception as e:
        coral_ts = EXAMPLE_CORAL.copy()
        public_data_warn = "ê³µê°œ ë°ì´í„°(GCBD) ë‹¤ìš´ë¡œë“œ ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨ â€” ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤."
except Exception as e:
    coral_ts = EXAMPLE_CORAL.copy()
    public_data_warn = "ê³µê°œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ â€” ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤."

# Ensure no future dates
coral_ts = drop_future_dates(coral_ts, date_col="date")

if public_data_warn:
    st.warning(public_data_warn)

# Left: show coral bleaching time series (ìµœê·¼ 45ë…„ ë¹„ìœ¨ ê·¸ë˜í”„)
with col1:
    st.subheader("ì‚°í˜¸ì´ˆ ë°±í™” í˜„ìƒ ë¹„ìœ¨ (ì—°ë³„, ê³µê°œ ë°ì´í„° ê¸°ë°˜ â€” ìë™ ì§‘ê³„)")
    # If data has more than 45 years, take last 45
    coral_ts = coral_ts.sort_values("date")
    if len(coral_ts) > 45:
        coral_plot_df = coral_ts.tail(45)
    else:
        coral_plot_df = coral_ts
    coral_plot_df = coral_plot_df.reset_index(drop=True)
    # Plotly line
    fig_coral = px.line(coral_plot_df, x="date", y=coral_plot_df.columns[1],
                        labels={"date":"ì—°ë„", coral_plot_df.columns[1]:"ë°±í™”ìœ¨ (%)"},
                        title="ìµœê·¼ ì—°ë„ë³„ ì‚°í˜¸ ë°±í™” í˜„ìƒ ë¹„ìœ¨")
    fig_coral.update_traces(mode="lines+markers")
    st.plotly_chart(fig_coral, use_container_width=True)

    # CSV ë‹¤ìš´ë¡œë“œ
    csv_buf = coral_plot_df.to_csv(index=False).encode('utf-8')
    st.download_button("ì‚°í˜¸ë°±í™”_ì—°ë³„_ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", data=csv_buf, file_name="coral_bleaching_timeseries.csv", mime="text/csv")

# ì•„ë˜: SST ë° ì‚°ì„±í™” ìš”ì•½ (ê°„ë‹¨)
st.markdown("---")
st.subheader("ë°”ë‹¤ ìˆ˜ì˜¨(SST) ë° í•´ì–‘ ì‚°ì„±í™” ê°œìš” (ê³µê°œ ë°ì´í„° ìš”ì•½)")
col_a, col_b = st.columns(2)

# Try to load SST anomaly timeseries (best-effort via NOAA OISST or fallback)
sst_warn = None
try:
    # For simplicity attempt to fetch a small pre-aggregated CSV (if exists). Otherwise use example.
    # NOAA OISST is typically a large netCDF; here we attempt a lightweight approach: try to fetch a small sample CSV
    # (This is a best-effort â€” if NOAA OISST CSV isn't available, fallback.)
    sst_example_url = "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/access/avhrr/2020/avhrr-only-20200101.nc"
    # Attempt HEAD request to check availability (not download large file)
    head = requests.head("https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html", timeout=8)
    # We'll use EXAMPLE_SST for plotting to avoid heavy downloads
    sst_df = EXAMPLE_SST.copy()
    sst_warn = "NOAA OISST ì›ë°ì´í„° ì ‘ê·¼ì€ ëŒ€ìš©ëŸ‰ì´ë¯€ë¡œ ì˜ˆì‹œ SST ì‹œê³„ì—´ë¡œ ëŒ€ì²´ í‘œì‹œí•©ë‹ˆë‹¤. (ì•±ì˜ ì£¼ì„ì— OISST ì ‘ê·¼ URL í¬í•¨)"
except Exception:
    sst_df = EXAMPLE_SST.copy()
    sst_warn = "SST ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ â€” ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤."

sst_df = drop_future_dates(sst_df, date_col="date")

with col_a:
    st.markdown("**í•´ì–‘ í‘œì¸µ ìˆ˜ì˜¨(SST) ì´ìƒì¹˜(ì˜ˆì‹œ)**")
    fig_sst = px.area(sst_df, x="date", y=sst_df.columns[1],
                      labels={"date":"ì—°ë„", sst_df.columns[1]:"SST ì´ìƒì¹˜ (Â°C)"},
                      title="í•´ì–‘ í‘œì¸µ ìˆ˜ì˜¨ ì´ìƒì¹˜ (ì›”ë³„, ì˜ˆì‹œ/ìš”ì•½)")
    st.plotly_chart(fig_sst, use_container_width=True)
    st.download_button("SST_ì‹œê³„ì—´_ë‹¤ìš´ë¡œë“œ (CSV)", data=sst_df.to_csv(index=False).encode('utf-8'),
                       file_name="sst_timeseries.csv", mime="text/csv")

with col_b:
    st.markdown("**í•´ì–‘ ì‚°ì„±í™”(ì˜ˆì‹œ)**")
    acid_df = EXAMPLE_ACID.copy()
    acid_df = drop_future_dates(acid_df, date_col="date")
    fig_acid = px.line(acid_df, x="date", y="surface_pH",
                       labels={"date":"ì—°ë„", "surface_pH":"í‘œì¸µ pH"},
                       title="í‘œì¸µ pH ì¶”ì„¸ (ì—°ë³„, ì˜ˆì‹œ)")
    st.plotly_chart(fig_acid, use_container_width=True)
    st.download_button("í•´ì–‘ì‚°ì„±í™”_ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", data=acid_df.to_csv(index=False).encode('utf-8'),
                       file_name="ocean_acidification_timeseries.csv", mime="text/csv")

if sst_warn:
    st.info(sst_warn)

st.markdown("---")
st.info("ê³µê°œ ë°ì´í„° ì ‘ê·¼ì€ ì‹œë„ë˜ì—ˆìœ¼ë©°, ëŒ€ìš©ëŸ‰/ì ‘ê·¼ ì œí•œ ë“±ìœ¼ë¡œ ì¸í•´ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œ ë‚´ ì£¼ì„ì— ì›ë³¸ ë°ì´í„° URLì„ ë‚¨ê²¼ìŠµë‹ˆë‹¤.")

# ---------- ì„¹ì…˜ 2: ì‚¬ìš©ì ì…ë ¥(í”„ë¡¬í”„íŠ¸) ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ----------
st.header("ğŸ“ ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ (ì œê³µëœ ë³´ê³ ì„œ ë‚´ìš©ë§Œ í™œìš©)")

st.markdown("**ì‚¬ìš©ì ì œê³µ ë³´ê³ ì„œ ìš”ì•½(ì…ë ¥ ë‚´ìš©)**")
st.write("ë³´ê³ ì„œ ì œëª©(ê°€ì œ): ì—­ëŒ€ ìµœì•…ì˜ ë°”ë‹¤ ê·¸ë¦¬ê³  ë” ìµœì•…ì´ ë  ë°”ë‹¤.")
st.write("ì£¼ìš” ë‚´ìš©: ì‚°í˜¸ ë°±í™”, í•´ì–‘ ì‚°ì„±í™”, ê³ ìˆ˜ì˜¨ì— ë”°ë¥¸ ì–´ë¥˜ íì‚¬ ë“±. ì°¸ê³ ìë£Œ ë§í¬ (ì œê³µë¨).")

# Per mission: DO NOT ask for upload; use only provided CSV/images/ì„¤ëª… from the prompt.
# The prompt specified two visualizations:
#  - (ë³¸ë¡ 1) ìµœê·¼ 45ë…„ê°„ ì‚°í˜¸ì´ˆ ë°±í™” í˜„ìƒ ë¹„ìœ¨ (ê³µê°œë°ì´í„° ì‚¬ìš©)
#  - (ë³¸ë¡ 2) í•´ì–‘ ì‚°ì„±í™”, ê³ ìˆ˜ì˜¨, ì–´ë¥˜ íì‚¬ ì˜í–¥ í†µê³„ (ì‚¬ìš©ì ì œê³µ ë§í¬ í¬í•¨)
#
# We will build visualizations using:
#  - coral_plot_df (already from ê³µê°œ / ì˜ˆì‹œ) for ë³¸ë¡ 1
#  - For ë³¸ë¡ 2: construct a composite panel combining SST anomaly (sst_df), surface_pH (acid_df),
#    and a synthetic 'fish_mortality_index' derived from SST anomalies.

# Prepareë³¸ë¡ 1 (45ë…„)
st.subheader("ë³¸ë¡  1 â€” ìµœê·¼ 45ë…„ê°„ ì‚°í˜¸ì´ˆ ë°±í™” í˜„ìƒ ë¹„ìœ¨ (ë³´ê³ ì„œìš©)")
coral_for_report = coral_plot_df.copy()
# Ensure x-axis yearly labels
fig_report_coral = px.area(coral_for_report, x="date", y=coral_for_report.columns[1],
                           labels={"date":"ì—°ë„", coral_for_report.columns[1]:"ë°±í™”ìœ¨ (%)"},
                           title="ë³´ê³ ì„œìš©: ìµœê·¼ 45ë…„ ì‚°í˜¸ ë°±í™”ìœ¨ (ì—°ë³„)")
st.plotly_chart(fig_report_coral, use_container_width=True)

# Prepareë³¸ë¡ 2 (ë³µí•© ì˜í–¥ ì‹œê°í™”)
st.subheader("ë³¸ë¡  2 â€” í•´ì–‘ ì‚°ì„±í™”Â·ê³ ìˆ˜ì˜¨Â·ì–´ë¥˜ íì‚¬ ì˜í–¥ (ë³µí•© ì‹œê°í™”)")

# Build a merged timeline for plotting (resample monthly->yearly where necessary)
# Use sst_df (monthly) -> annual mean anomaly; acid_df yearly pH; create synthetic fish mortality index.
try:
    sst_annual = sst_df.copy()
    sst_annual['date'] = pd.to_datetime(sst_annual['date'], errors='coerce')
    sst_annual['year'] = sst_annual['date'].dt.year
    sst_ann = sst_annual.groupby('year')[sst_annual.columns[1]].mean().reset_index()
    sst_ann['date'] = pd.to_datetime(sst_ann['year'].astype(str) + "-01-01")
    sst_ann = sst_ann[['date', sst_ann.columns[1]]].rename(columns={sst_ann.columns[1]:'sst_anomaly_mean'})
except Exception:
    sst_ann = pd.DataFrame({"date": pd.date_range(start="1980-01-01", periods=35, freq="Y"),
                            "sst_anomaly_mean": np.linspace( -0.2, 0.9, 35)})

acid_ann = acid_df.copy()
acid_ann['date'] = pd.to_datetime(acid_ann['date'], errors='coerce')
# Align years
merged = pd.merge(coral_for_report[['date', coral_for_report.columns[1]]].rename(columns={coral_for_report.columns[1]:'bleaching_rate_percent'}),
                  sst_ann, on='date', how='outer')
merged = pd.merge(merged, acid_ann[['date', 'surface_pH']], on='date', how='outer')
merged = merged.sort_values('date').reset_index(drop=True)

# If fish mortality index absent, create synthetic index:
if 'fish_mortality_index' not in merged.columns:
    # heuristic: higher sst_anomaly and lower pH increase mortality index
    # normalize sst_anomaly_mean and (8.2 - pH) to 0-100
    merged['sst_norm'] = (merged['sst_anomaly_mean'] - merged['sst_anomaly_mean'].min()) / (merged['sst_anomaly_mean'].max() - merged['sst_anomaly_mean'].min() + 1e-9)
    merged['pH_drop'] = 8.2 - merged['surface_pH']  # positive if pH decreased below 8.2
    merged['pH_norm'] = (merged['pH_drop'] - merged['pH_drop'].min()) / (merged['pH_drop'].max() - merged['pH_drop'].min() + 1e-9)
    merged['fish_mortality_index'] = (0.7 * merged['sst_norm'] + 0.3 * merged['pH_norm']) * 100
    merged['fish_mortality_index'] = merged['fish_mortality_index'].fillna(method='ffill').fillna(0)

# Drop future dates
merged = drop_future_dates(merged, date_col='date')

# Show triple-axis subplot using plotly (two y-axes + index)
fig2 = px.line(merged, x='date', y='bleaching_rate_percent', labels={'date':'ì—°ë„', 'bleaching_rate_percent':'ë°±í™”ìœ¨ (%)'}, title="í•´ì–‘ ê³ ìˆ˜ì˜¨Â·ì‚°ì„±í™”Â·ì–´ë¥˜ íì‚¬(ì§€ìˆ˜) ë¹„êµ (ì—°ë³„)")
# Add sst and fish index as additional traces
fig2.add_scatter(x=merged['date'], y=merged['sst_anomaly_mean'], mode='lines+markers', name='SST ì—°í‰ê·  ì´ìƒì¹˜ (Â°C)', yaxis='y2')
fig2.add_scatter(x=merged['date'], y=merged['fish_mortality_index'], mode='lines+markers', name='ì–´ë¥˜ íì‚¬ ì§€ìˆ˜ (í•©ì„±)', yaxis='y3')

# Update layout with multiple Y axes
fig2.update_layout(
    yaxis=dict(title='ë°±í™”ìœ¨ (%)'),
    yaxis2=dict(title='SST ì´ìƒì¹˜ (Â°C)', overlaying='y', side='right', position=0.95),
    yaxis3=dict(title='ì–´ë¥˜ íì‚¬ ì§€ìˆ˜ (ì„ì˜ë‹¨ìœ„)', anchor='free', overlaying='y', side='right', position=1.0),
    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
)
st.plotly_chart(fig2, use_container_width=True)

# Download merged CSV for report usage
st.download_button("ë³¸ë¡ 2_ë³µí•©_ì „ì²˜ë¦¬_ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", data=merged.to_csv(index=False).encode('utf-8'),
                   file_name="report_combined_ocean_data.csv", mime="text/csv")

st.markdown("---")
st.subheader("ê²°ë¡  ë° ê¶Œê³  (ë³´ê³ ì„œì— ë“¤ì–´ê°ˆ ë‚´ìš© ìë™ ì œì•ˆ)")
st.write("""
- ì‚°í˜¸ ë°±í™” í˜„ìƒì€ ì „ ì„¸ê³„ì ìœ¼ë¡œ í™•ì‚° ì¤‘ì´ë©°(ê³µì‹ ë°ì´í„°/ë³´ê³ ì„œ ì°¸ì¡°), í•´ìˆ˜ì˜¨ ìƒìŠ¹ ë° í•´ì–‘ ì‚°ì„±í™”ê°€ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.
- ê¶Œê³ :
  1. ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œ ì €ê°ì„ ìœ„í•œ ì •ì±… ë° ê°œì¸ í–‰ë™(ëŒ€ì¤‘êµí†µ ì´ìš©, ë…¸í”Œë¼ìŠ¤í‹± ì‹¤ì²œ ë“±) ê°•í™”
  2. í•´ì–‘ ë³´í˜¸êµ¬ì—­ í™•ëŒ€ ë° ì‚°í˜¸ ë³µì› í”„ë¡œì íŠ¸ íˆ¬ì
  3. ì¥ê¸° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê°•í™”(ìœ„ì„±+í˜„ì¥ ê´€ì¸¡ í†µí•©)
""")

st.markdown("**ì°¸ê³ ìë£Œ(ì•±ì—ì„œ ì‚¬ìš©/ì°¸ì¡°ëœ ë§í¬)**")
st.write("- GCBD ë…¼ë¬¸/ë°ì´í„°: https://www.nature.com/articles/s41597-022-01121-y")
st.write("- NOAA Coral Reef Watch: https://coralreefwatch.noaa.gov/")
st.write("- NOAA OISST: https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html")
st.write("- Ocean Carbon & Acidification (OCADS): https://www.ncei.noaa.gov/products/ocean-carbon-acidification-data-system")
st.write("- í•œêµ­ ê´€ë ¨: " + KCI_KISTI)
st.write("- NIFS ë³´ê³ ì„œ PDF: " + NIFS_PDF)

st.markdown("---")
st.caption("ì•± ë…¸íŠ¸: ê³µê°œ ë°ì´í„°ëŠ” ì›ë¬¸ í¬ë§·(ì˜ˆ: netCDF, FTP ë“±)ìœ¼ë¡œ ì œê³µë˜ëŠ” ê²½ìš°ê°€ ë§ì•„ ì‹¤ì‚¬ìš© ì‹œì—ëŠ” ì ì ˆí•œ ì¸ì¦Â·ë‹¤ìš´ë¡œë“œÂ·ì²˜ë¦¬(ì˜ˆ: xarray.open_dataset ë“±)ë¥¼ ì¶”ê°€ë¡œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì•±ì€ 'ê³µê°œ ë°ì´í„° ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´' ë¡œì§ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
